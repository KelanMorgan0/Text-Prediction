{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text Prediction\n",
    "\n",
    "data received from [Sentiment140 dataset with 1.6 million tweets](https://www.kaggle.com/datasets/kazanova/sentiment140)\n",
    "\n",
    "# Imports"
   ],
   "id": "edce76f071657a9b"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T20:58:31.065323Z",
     "start_time": "2025-03-24T20:58:12.643943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Dataset",
   "id": "d88fad4ef1a83dcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T20:58:38.888302Z",
     "start_time": "2025-03-24T20:58:31.076407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"Data/twitter_data.csv\", encoding=\"latin-1\", header=None)\n",
    "data.columns = [\"sentiment\", \"id\", \"date\", \"flag\", \"user\", \"text\"]"
   ],
   "id": "ed2a4b0fe9f454da",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create a smaller subset of the data to make it easier to work with\n",
    "- only get the text and 50,000 random rows\n",
    "- make all text lower case\n",
    "- make the strings lists of words"
   ],
   "id": "6476ed0bd2e02c1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T20:58:39.191771Z",
     "start_time": "2025-03-24T20:58:38.943257Z"
    }
   },
   "cell_type": "code",
   "source": "tweets = data[\"text\"].sample(50000).str.lower().tolist()",
   "id": "ba3feed4e33fb8cb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "- remove all hashtags and mentions\n",
    "- remove all urls\n",
    "- ensure only letters, numbers and punctuation symbols are left\n",
    "- add all cleaned tweets to one string"
   ],
   "id": "ce279f825928986c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T20:58:39.753070Z",
     "start_time": "2025-03-24T20:58:39.221052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clean_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9\\s.,!?]\", \"\", tweet)\n",
    "    clean_tweets.append(tweet)\n",
    "\n",
    "all_text = \" \".join(clean_tweets)"
   ],
   "id": "1bd91731d5b71e1d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# convert characters to numerical data",
   "id": "ae2ff77518aad9dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T20:59:07.261707Z",
     "start_time": "2025-03-24T20:58:39.779246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = sorted(set(all_text))\n",
    "\n",
    "# index the characters\n",
    "char_to_index = {c: i for i, c in enumerate(chars)}\n",
    "index_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# Length of input\n",
    "length = 40\n",
    "# num of steps to do\n",
    "step = 3\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(all_text) - length, step):\n",
    "    X.append(all_text[i:i + length])\n",
    "    y.append(all_text[i + length])\n",
    "\n",
    "# Convert characters to numbers\n",
    "X_encoded = np.zeros((len(X), length, len(chars)), dtype=bool)\n",
    "y_encoded = np.zeros((len(y), len(chars)), dtype=bool)\n",
    "\n",
    "# loop the number of times of x, add all encoded x values to x_encoded and all y values to y_encoded\n",
    "for i, seq in enumerate(X):\n",
    "    for t, char in enumerate(seq):\n",
    "        X_encoded[i, t, char_to_index[char]] = 1\n",
    "    y_encoded[i, char_to_index[y[i]]] = 1"
   ],
   "id": "28e7f585d16dc3dd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train RNN Model",
   "id": "addab8010bd08a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T21:53:09.186401Z",
     "start_time": "2025-03-24T20:59:07.276383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(length, len(chars))),\n",
    "    Dense(len(chars), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_encoded, y_encoded, batch_size=256, epochs=5, validation_split=0.1)"
   ],
   "id": "a22ee545a5ebbdb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelan\\OneDrive\\Documents\\GitHub\\Cat-Dog-Classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m3927/3927\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m827s\u001B[0m 210ms/step - accuracy: 0.2958 - loss: 2.4999 - val_accuracy: 0.4054 - val_loss: 2.0519\n",
      "Epoch 2/5\n",
      "\u001B[1m3927/3927\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m625s\u001B[0m 159ms/step - accuracy: 0.4233 - loss: 2.0017 - val_accuracy: 0.4525 - val_loss: 1.8924\n",
      "Epoch 3/5\n",
      "\u001B[1m3927/3927\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m597s\u001B[0m 152ms/step - accuracy: 0.4602 - loss: 1.8649 - val_accuracy: 0.4727 - val_loss: 1.8106\n",
      "Epoch 4/5\n",
      "\u001B[1m3927/3927\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m594s\u001B[0m 151ms/step - accuracy: 0.4804 - loss: 1.7892 - val_accuracy: 0.4879 - val_loss: 1.7567\n",
      "Epoch 5/5\n",
      "\u001B[1m3927/3927\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m598s\u001B[0m 152ms/step - accuracy: 0.4954 - loss: 1.7352 - val_accuracy: 0.5000 - val_loss: 1.7211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ee89fef5d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Function to predict the next Characters",
   "id": "d57702e7afb9aa76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:47:23.008950Z",
     "start_time": "2025-03-28T19:47:23.001960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(userInput, num_chars):\n",
    "    generated = userInput\n",
    "    for _ in range(num_chars):\n",
    "\n",
    "        # Encode the user input\n",
    "        x_pred = np.zeros((1, length, len(chars)))\n",
    "        for t, char in enumerate(userInput):\n",
    "            x_pred[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        # Predict the next character\n",
    "        # ensure it grabs a character that makes sense by getting a random value that is likely to be used\n",
    "        preds = model.predict(x_pred)[0]\n",
    "        preds = np.log(preds) / 0.4\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        next_index = np.random.choice(len(chars), p=preds)\n",
    "\n",
    "        # Convert new character to char\n",
    "        next_char = index_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        userInput = userInput[1:] + next_char  # Slide the window\n",
    "\n",
    "    return generated"
   ],
   "id": "617719a7fb31cce",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:47:28.303055Z",
     "start_time": "2025-03-28T19:47:26.841903Z"
    }
   },
   "cell_type": "code",
   "source": "print(predict(\"i have\", 20))",
   "id": "1df6428f6fdddb88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "i have     s   y      e s \n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
